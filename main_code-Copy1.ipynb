{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch \n",
    "!pip install numpy\n",
    "!pip install scikit-learn\n",
    "!pip install opencv-python\n",
    "!pip install pandas\n",
    "!pip install seaborn\n",
    "!pip install matplotlib\n",
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptions\n",
    "Python script with specific command-line arguments using the subprocess module. It begins by defining the command to be executed, which includes the Python interpreter, and two arguments: --kernel_type and --data_set "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The kernels used in the code are:\n",
    "\n",
    "- **non**  - no kernel are used. \n",
    "- **exponential**\n",
    "- **simple_Sum**\n",
    "- **concatenation**\n",
    "- **rbf** (Radial Basis Function)\n",
    "- **sigmoid**\n",
    "- **Matern**\n",
    "- **laplician**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The datasets used in the code are:\n",
    "\n",
    "- **cifar10**\n",
    "- **cifar100**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models used in the code are:\n",
    "\n",
    "- **SimCLR**\n",
    "- **ResNet-50**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "command = ['python', 'cifar.py', '--kernel_type', 'non', '--data_set', 'cifar10']\n",
    "process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True)\n",
    "for line in iter(process.stdout.readline, ''):\n",
    "    print(line.strip())  # Print each line as it is read from stdout\n",
    "\n",
    "process.stdout.close()\n",
    "process.wait()\n",
    "\n",
    "stderr = process.stderr.read()\n",
    "if stderr:\n",
    "    print(\"Error:\")\n",
    "    print(stderr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "command = ['python', 'cifar.py', '--kernel_type', 'exponential', '--data_set', 'cifar10']\n",
    "process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True)\n",
    "for line in iter(process.stdout.readline, ''):\n",
    "    print(line.strip())  # Print each line as it is read from stdout\n",
    "\n",
    "process.stdout.close()\n",
    "process.wait()\n",
    "\n",
    "stderr = process.stderr.read()\n",
    "if stderr:\n",
    "    print(\"Error:\")\n",
    "    print(stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "command = ['python', 'cifar.py', '--kernel_type', 'simple_Sum', '--data_set', 'cifar10']\n",
    "process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True)\n",
    "for line in iter(process.stdout.readline, ''):\n",
    "    print(line.strip())  # Print each line as it is read from stdout\n",
    "\n",
    "process.stdout.close()\n",
    "process.wait()\n",
    "\n",
    "stderr = process.stderr.read()\n",
    "if stderr:\n",
    "    print(\"Error:\")\n",
    "    print(stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "command = ['python', 'cifar.py', '--kernel_type', 'concatenation', '--data_set', 'cifar10']\n",
    "process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True)\n",
    "for line in iter(process.stdout.readline, ''):\n",
    "    print(line.strip())  # Print each line as it is read from stdout\n",
    "\n",
    "process.stdout.close()\n",
    "process.wait()\n",
    "\n",
    "stderr = process.stderr.read()\n",
    "if stderr:\n",
    "    print(\"Error:\")\n",
    "    print(stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "command = ['python', 'cifar.py', '--kernel_type', 'rbf', '--data_set', 'cifar10']\n",
    "process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True)\n",
    "for line in iter(process.stdout.readline, ''):\n",
    "    print(line.strip())  # Print each line as it is read from stdout\n",
    "\n",
    "process.stdout.close()\n",
    "process.wait()\n",
    "\n",
    "stderr = process.stderr.read()\n",
    "if stderr:\n",
    "    print(\"Error:\")\n",
    "    print(stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "command = ['python', 'cifar.py', '--kernel_type', 'sigmoid', '--data_set', 'cifar10']\n",
    "process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True)\n",
    "for line in iter(process.stdout.readline, ''):\n",
    "    print(line.strip())  # Print each line as it is read from stdout\n",
    "\n",
    "process.stdout.close()\n",
    "process.wait()\n",
    "\n",
    "stderr = process.stderr.read()\n",
    "if stderr:\n",
    "    print(\"Error:\")\n",
    "    print(stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "command = ['python', 'cifar.py', '--kernel_type', 'Matern', '--data_set', 'cifar10']\n",
    "process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True)\n",
    "for line in iter(process.stdout.readline, ''):\n",
    "    print(line.strip())  # Print each line as it is read from stdout\n",
    "\n",
    "process.stdout.close()\n",
    "process.wait()\n",
    "\n",
    "stderr = process.stderr.read()\n",
    "if stderr:\n",
    "    print(\"Error:\")\n",
    "    print(stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "command = ['python', 'cifar.py', '--kernel_type', 'laplician', '--data_set', 'cifar10']\n",
    "process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True)\n",
    "for line in iter(process.stdout.readline, ''):\n",
    "    print(line.strip())  # Print each line as it is read from stdout\n",
    "\n",
    "process.stdout.close()\n",
    "process.wait()\n",
    "\n",
    "stderr = process.stderr.read()\n",
    "if stderr:\n",
    "    print(\"Error:\")\n",
    "    print(stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cifar100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "command = ['python', 'cifar.py', '--kernel_type', 'non', '--data_set', 'cifar100']\n",
    "process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True)\n",
    "for line in iter(process.stdout.readline, ''):\n",
    "    print(line.strip())  # Print each line as it is read from stdout\n",
    "\n",
    "process.stdout.close()\n",
    "process.wait()\n",
    "\n",
    "stderr = process.stderr.read()\n",
    "if stderr:\n",
    "    print(\"Error:\")\n",
    "    print(stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "command = ['python', 'cifar.py', '--kernel_type', 'exponential', '--data_set', 'cifar100']\n",
    "process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True)\n",
    "for line in iter(process.stdout.readline, ''):\n",
    "    print(line.strip())  # Print each line as it is read from stdout\n",
    "\n",
    "process.stdout.close()\n",
    "process.wait()\n",
    "\n",
    "stderr = process.stderr.read()\n",
    "if stderr:\n",
    "    print(\"Error:\")\n",
    "    print(stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "command = ['python', 'cifar.py', '--kernel_type', 'simple_Sum', '--data_set', 'cifar100']\n",
    "process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True)\n",
    "for line in iter(process.stdout.readline, ''):\n",
    "    print(line.strip())  # Print each line as it is read from stdout\n",
    "\n",
    "process.stdout.close()\n",
    "process.wait()\n",
    "\n",
    "stderr = process.stderr.read()\n",
    "if stderr:\n",
    "    print(\"Error:\")\n",
    "    print(stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "command = ['python', 'cifar.py', '--kernel_type', 'concatenation', '--data_set', 'cifar100']\n",
    "process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True)\n",
    "for line in iter(process.stdout.readline, ''):\n",
    "    print(line.strip())  # Print each line as it is read from stdout\n",
    "\n",
    "process.stdout.close()\n",
    "process.wait()\n",
    "\n",
    "stderr = process.stderr.read()\n",
    "if stderr:\n",
    "    print(\"Error:\")\n",
    "    print(stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "command = ['python', 'cifar.py', '--kernel_type', 'rbf', '--data_set', 'cifar100']\n",
    "process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True)\n",
    "for line in iter(process.stdout.readline, ''):\n",
    "    print(line.strip())  # Print each line as it is read from stdout\n",
    "\n",
    "process.stdout.close()\n",
    "process.wait()\n",
    "\n",
    "stderr = process.stderr.read()\n",
    "if stderr:\n",
    "    print(\"Error:\")\n",
    "    print(stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "command = ['python', 'cifar.py', '--kernel_type', 'sigmoid', '--data_set', 'cifar100']\n",
    "process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True)\n",
    "for line in iter(process.stdout.readline, ''):\n",
    "    print(line.strip())  # Print each line as it is read from stdout\n",
    "\n",
    "process.stdout.close()\n",
    "process.wait()\n",
    "\n",
    "stderr = process.stderr.read()\n",
    "if stderr:\n",
    "    print(\"Error:\")\n",
    "    print(stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "command = ['python', 'cifar.py', '--kernel_type', 'Matern', '--data_set', 'cifar100']\n",
    "process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True)\n",
    "for line in iter(process.stdout.readline, ''):\n",
    "    print(line.strip())  # Print each line as it is read from stdout\n",
    "\n",
    "process.stdout.close()\n",
    "process.wait()\n",
    "\n",
    "stderr = process.stderr.read()\n",
    "if stderr:\n",
    "    print(\"Error:\")\n",
    "    print(stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "command = ['python', 'cifar.py', '--kernel_type', 'laplician', '--data_set', 'cifar100']\n",
    "process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True)\n",
    "for line in iter(process.stdout.readline, ''):\n",
    "    print(line.strip())  # Print each line as it is read from stdout\n",
    "\n",
    "process.stdout.close()\n",
    "process.wait()\n",
    "\n",
    "stderr = process.stderr.read()\n",
    "if stderr:\n",
    "    print(\"Error:\")\n",
    "    print(stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# Define the commands and parameters\n",
    "datasets = ['cifar10', 'cifar100']\n",
    "kernels = ['simclr reproduction', 'exponential', 'simple sum', 'concatenation', 'rbf', 'sigmoid', 'Matern', 'laplacian']\n",
    "\n",
    "# Function to run commands and save logs\n",
    "def run_and_save_logs(dataset, kernel_type):\n",
    "   \n",
    "    command = ['python', 'cifar_new.py', '--kernel_type', kernel_type, '--data_set', dataset]\n",
    "    log_file = f'{dataset}_{kernel_type}_log.txt'\n",
    "    \n",
    "    with open(log_file, 'w') as file:\n",
    "        process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True)\n",
    "        \n",
    "        # Collect output and error streams\n",
    "        stdout, stderr = process.communicate()\n",
    "        \n",
    "        file.write(stdout)  # Write each line to the file\n",
    "        \n",
    "        if stderr:\n",
    "            file.write(\"\\nError:\\n\")\n",
    "            file.write(stderr)\n",
    "\n",
    "# Run commands for all datasets and kernel types\n",
    "for dataset in datasets:\n",
    "    for kernel in kernels:\n",
    "        run_and_save_logs(dataset, kernel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.table import Table\n",
    "import numpy as np\n",
    "\n",
    "# Function to extract validation binary accuracy from a log file\n",
    "def extract_validation_accuracy(log_path):\n",
    "    accuracies = []\n",
    "    with open(log_path, 'r') as file:\n",
    "        log = file.read()\n",
    "    \n",
    "    # Adjust the regex pattern based on log file format\n",
    "    pattern = re.compile(r\"VALIDATION BINARY ACCURACY:\\s*(\\d+\\.\\d+)\")\n",
    "    \n",
    "    for match in pattern.finditer(log):\n",
    "        accuracies.append(float(match.group(1)))\n",
    "    \n",
    "    return accuracies\n",
    "\n",
    "# Extract the validation accuracy at the 20th and 40th epochs\n",
    "def extract_20th_and_40th_epoch_accuracy(log_path):\n",
    "    accuracies = extract_validation_accuracy(log_path)\n",
    "    \n",
    "    epoch_20_accuracy = accuracies[19] if len(accuracies) >= 20 else None\n",
    "    epoch_40_accuracy = accuracies[-1] if len(accuracies) >= 40 else None\n",
    "    \n",
    "    return epoch_20_accuracy, epoch_40_accuracy\n",
    "\n",
    "# Extract data from logs for all datasets and kernels\n",
    "def extract_data_from_logs(datasets, kernels):\n",
    "    results = []\n",
    "    for dataset in datasets:\n",
    "        for kernel in kernels:\n",
    "            log_file = f'{dataset}_{kernel}_log.txt'\n",
    "            epoch_20_accuracy, epoch_40_accuracy = extract_20th_and_40th_epoch_accuracy(log_file)\n",
    "            if epoch_20_accuracy is not None and epoch_40_accuracy is not None:\n",
    "                results.append([dataset, kernel, epoch_20_accuracy, epoch_40_accuracy])\n",
    "    return results\n",
    "\n",
    "# Define datasets and kernels for extraction\n",
    "datasets = ['cifar10', 'cifar100']\n",
    "kernels = ['simclr reproduction', 'exponential', 'simple sum', 'concatenation', 'rbf', 'sigmoid', 'Matern', 'laplacian']\n",
    "\n",
    "# Extract and display data\n",
    "results = extract_data_from_logs(datasets, kernels)\n",
    "df = pd.DataFrame(results, columns=['Dataset', 'Kernel Type', 'Validation Accuracy (Epoch 20)', 'Validation Accuracy (Epoch 40)'])\n",
    "\n",
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "# Hide the axes\n",
    "ax.xaxis.set_visible(False)\n",
    "ax.yaxis.set_visible(False)\n",
    "ax.set_frame_on(False)\n",
    "\n",
    "# Create a table\n",
    "table = Table(ax, bbox=[0, 0, 1, 1])\n",
    "\n",
    "# Add cells to the table\n",
    "n_rows, n_cols = df.shape\n",
    "for (i, j), val in np.ndenumerate(df.values):\n",
    "    table.add_cell(i, j, width=1.0/n_cols, height=1.0/n_rows, text=val, loc='center', facecolor='white')\n",
    "\n",
    "# Add column headers\n",
    "for j, col in enumerate(df.columns):\n",
    "    table.add_cell(-1, j, width=1.0/n_cols, height=1.0/n_rows, text=col, loc='center', facecolor='lightgrey')\n",
    "\n",
    "# Add row headers\n",
    "for i, row in enumerate(df.index):\n",
    "    table.add_cell(i, -1, width=1.0/n_cols, height=1.0/n_rows, text=row, loc='center', facecolor='lightgrey')\n",
    "\n",
    "# Add the table to the plot\n",
    "ax.add_table(table)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Function to extract validation binary accuracy from a log file\n",
    "def extract_validation_accuracy(log_path):\n",
    "    accuracies = []\n",
    "    with open(log_path, 'r') as file:\n",
    "        log = file.read()\n",
    "    \n",
    "    # Adjust the regex pattern based on log file format\n",
    "    pattern = re.compile(r\"VALIDATION BINARY ACCURACY:\\s*(\\d+\\.\\d+)\")\n",
    "    \n",
    "    for match in pattern.finditer(log):\n",
    "        accuracies.append(float(match.group(1)))\n",
    "    \n",
    "    return accuracies\n",
    "\n",
    "# Extract the validation accuracy at the 20th and 40th epochs\n",
    "def extract_20th_and_40th_epoch_accuracy(log_path):\n",
    "    accuracies = extract_validation_accuracy(log_path)\n",
    "    \n",
    "    epoch_20_accuracy = accuracies[19] if len(accuracies) >= 20 else None\n",
    "    epoch_40_accuracy = accuracies[39] if len(accuracies) >= 40 else None\n",
    "    \n",
    "    return epoch_20_accuracy, epoch_40_accuracy\n",
    "\n",
    "# Extract data from logs for all datasets and kernels\n",
    "def extract_data_from_logs(datasets, kernels):\n",
    "    results = []\n",
    "    for dataset in datasets:\n",
    "        for kernel in kernels:\n",
    "#             if kernel == 'non':\n",
    "#                 kernel = 'simclr reproduction'\n",
    "#             if kernel == 'laplician':\n",
    "#                 kernel = 'laplacian'\n",
    "#             if kernel == 'simple_Sum':\n",
    "#                 kernel = 'simple sum'\n",
    "            log_file = f'{dataset}_{kernel}_log.txt'\n",
    "            epoch_20_accuracy, epoch_40_accuracy = extract_20th_and_40th_epoch_accuracy(log_file)\n",
    "            if epoch_20_accuracy is not None and epoch_40_accuracy is not None:\n",
    "                results.append([dataset, kernel, epoch_20_accuracy, epoch_40_accuracy])\n",
    "    return results\n",
    "\n",
    "# Define datasets and kernels for extraction\n",
    "datasets = ['cifar10', 'cifar100']\n",
    "kernels = ['simclr reproduction', 'exponential', 'simple sum', 'concatenation', 'rbf', 'sigmoid', 'Matern', 'laplacian']\n",
    "\n",
    "# Extract and display data\n",
    "results = extract_data_from_logs(datasets, kernels)\n",
    "df = pd.DataFrame(results, columns=['Dataset', 'Kernel Type', 'Accuracy(Epoch 20)', 'Accuracy(Epoch 40)'])\n",
    "\n",
    "# Round accuracy values for better display\n",
    "df['Accuracy(Epoch 20)'] = df['Accuracy(Epoch 20)'].round(4)\n",
    "df['Accuracy(Epoch 40)'] = df['Accuracy(Epoch 40)'].round(4)\n",
    "\n",
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots(figsize=(12, len(df)*0.5 + 2))\n",
    "ax.axis('tight')\n",
    "ax.axis('off')\n",
    "\n",
    "# Create table\n",
    "table = ax.table(cellText=df.values, colLabels=df.columns, cellLoc='center', loc='center')\n",
    "\n",
    "# Styling the table\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(10)\n",
    "table.scale(1, 1.5)  # Adjust row height\n",
    "\n",
    "# Color the header\n",
    "for (row, col), cell in table.get_celld().items():\n",
    "    if row == 0:\n",
    "        cell.set_facecolor('#6AA84F')\n",
    "        cell.set_text_props(weight='bold', color='white')\n",
    "    elif row % 2 == 0:\n",
    "        cell.set_facecolor('#E6E6E6')\n",
    "    else:\n",
    "        cell.set_facecolor('white')\n",
    "\n",
    "plt.title('Validation Accuracy at Epochs 20 and 40', fontsize=14, fontweight='bold', pad=20)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Function to extract validation binary accuracy from a log file\n",
    "def extract_validation_accuracy(log_path):\n",
    "    accuracies = []\n",
    "    with open(log_path, 'r') as file:\n",
    "        log = file.read()\n",
    "    \n",
    "    # Adjust the regex pattern based on log file format\n",
    "    pattern = re.compile(r\"VALIDATION BINARY ACCURACY:\\s*(\\d+\\.\\d+)\")\n",
    "    \n",
    "    for match in pattern.finditer(log):\n",
    "        accuracies.append(float(match.group(1)))\n",
    "    \n",
    "    return accuracies\n",
    "\n",
    "# Extract the validation accuracy at the 20th and 40th epochs\n",
    "def extract_20th_and_40th_epoch_accuracy(log_path):\n",
    "    accuracies = extract_validation_accuracy(log_path)\n",
    "    print(log_path)\n",
    "    \n",
    "    epoch_20_accuracy = accuracies[19] if len(accuracies) >= 20 else None\n",
    "    epoch_40_accuracy = accuracies[-1] if len(accuracies) >= 40 else None\n",
    "    \n",
    "    return epoch_20_accuracy, epoch_40_accuracy\n",
    "\n",
    "# Extract data from logs for all datasets and kernels\n",
    "def extract_data_from_logs(datasets, kernels):\n",
    "    results = []\n",
    "    for dataset in datasets:\n",
    "        for kernel in kernels:\n",
    " \n",
    "            log_file = f'{dataset}_{kernel}_log.txt'\n",
    "            epoch_20_accuracy, epoch_40_accuracy = extract_20th_and_40th_epoch_accuracy(log_file)\n",
    "            if epoch_20_accuracy is not None and epoch_40_accuracy is not None:\n",
    "                results.append([dataset, kernel, epoch_20_accuracy, epoch_40_accuracy])\n",
    "    return results\n",
    "\n",
    "# Define datasets and kernels for extraction\n",
    "datasets = ['cifar10', 'cifar100']\n",
    "kernels = ['simclr reproduction', 'exponential', 'simple sum', 'concatenation', 'rbf', 'sigmoid', 'Matern', 'laplacian']\n",
    "\n",
    "# Extract and display data\n",
    "results = extract_data_from_logs(datasets, kernels)\n",
    "df = pd.DataFrame(results, columns=['Dataset', 'Kernel Type', 'Validation Accuracy (Epoch 20)', 'Validation Accuracy (Epoch 40)'])\n",
    "\n",
    "# Plot the data\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "# Plotting\n",
    "width = 0.35  # Bar width\n",
    "x = np.arange(len(df))\n",
    "\n",
    "ax.bar(x - width/2, df['Validation Accuracy (Epoch 20)'], width, label='Epoch 20')\n",
    "ax.bar(x + width/2, df['Validation Accuracy (Epoch 40)'], width, label='Epoch 40')\n",
    "\n",
    "# Adding labels and title\n",
    "ax.set_xlabel('Dataset and Kernel Type')\n",
    "ax.set_ylabel('Validation Accuracy')\n",
    "ax.set_title('Validation Accuracy at Epoch 20 and 40 for Different Kernels')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels([f'{row.Dataset}\\n{row[\"Kernel Type\"]}' for _, row in df.iterrows()], rotation=45, ha=\"right\")\n",
    "\n",
    "# Adding a legend\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:max_harnot_contrastive] *",
   "language": "python",
   "name": "conda-env-max_harnot_contrastive-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "625px",
    "width": "382px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
